{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a48b0268",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-01-12T21:00:41.882028Z",
     "iopub.status.busy": "2022-01-12T21:00:41.881067Z",
     "iopub.status.idle": "2022-01-12T21:00:41.891605Z",
     "shell.execute_reply": "2022-01-12T21:00:41.892173Z",
     "shell.execute_reply.started": "2022-01-12T20:36:10.546847Z"
    },
    "papermill": {
     "duration": 0.044849,
     "end_time": "2022-01-12T21:00:41.892510",
     "exception": false,
     "start_time": "2022-01-12T21:00:41.847661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/rotten-tomatoes-reviews-dataset/rt-polarity-no-header.csv\n",
      "/kaggle/input/rotten-tomatoes-reviews-dataset/data_rt.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "# list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3274c487",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-12T21:00:41.937356Z",
     "iopub.status.busy": "2022-01-12T21:00:41.936629Z",
     "iopub.status.idle": "2022-01-12T21:00:42.007869Z",
     "shell.execute_reply": "2022-01-12T21:00:42.008408Z",
     "shell.execute_reply.started": "2022-01-12T20:36:37.062830Z"
    },
    "papermill": {
     "duration": 0.095618,
     "end_time": "2022-01-12T21:00:42.008606",
     "exception": false,
     "start_time": "2022-01-12T21:00:41.912988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>simplistic , silly and tedious .</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6830</th>\n",
       "      <td>1</td>\n",
       "      <td>another one of those estrogen overdose movies ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8600</th>\n",
       "      <td>1</td>\n",
       "      <td>scott delivers a terrific performance in this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4080</th>\n",
       "      <td>0</td>\n",
       "      <td>i didn't find much fascination in the swinging...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3079</th>\n",
       "      <td>0</td>\n",
       "      <td>if you're not the target demographic . . . thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>0</td>\n",
       "      <td>simply put , there should have been a more com...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0                  simplistic , silly and tedious . \n",
       "6830  1  another one of those estrogen overdose movies ...\n",
       "8600  1  scott delivers a terrific performance in this ...\n",
       "4080  0  i didn't find much fascination in the swinging...\n",
       "3079  0  if you're not the target demographic . . . thi...\n",
       "582   0  simply put , there should have been a more com..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the data with shuffling\n",
    "root = \"/kaggle/input/rotten-tomatoes-reviews-dataset/\"\n",
    "filename = \"rt-polarity-no-header.csv\"\n",
    "data = pd.read_csv(root+filename).sample(\n",
    "    frac = 1, random_state = 42)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d47d1ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-12T21:00:42.050497Z",
     "iopub.status.busy": "2022-01-12T21:00:42.049788Z",
     "iopub.status.idle": "2022-01-12T21:00:43.424375Z",
     "shell.execute_reply": "2022-01-12T21:00:43.424949Z",
     "shell.execute_reply.started": "2022-01-12T20:37:25.020426Z"
    },
    "papermill": {
     "duration": 1.397165,
     "end_time": "2022-01-12T21:00:43.425140",
     "exception": false,
     "start_time": "2022-01-12T21:00:42.027975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# with specifications customize rt-polarity data into a torchtext dataset\n",
    "\n",
    "from torchtext.utils import download_from_url, extract_archive\n",
    "from torchtext.data.datasets_utils import _RawTextIterableDataset\n",
    "from torchtext.data.datasets_utils import _wrap_split_argument\n",
    "from torchtext.data.datasets_utils import _add_docstring_header\n",
    "from torchtext.data.datasets_utils import _find_match\n",
    "from torchtext.data.datasets_utils import _create_dataset_directory\n",
    "from torchtext.data.datasets_utils import _create_data_from_csv\n",
    "import os\n",
    "\n",
    "NUM_LINES = {\n",
    "    'train': 8662,\n",
    "    'test': 2000,\n",
    "}\n",
    "\n",
    "DATASET_NAME = \"RTPolarity\"\n",
    "\n",
    "\n",
    "@_add_docstring_header(num_lines=NUM_LINES, num_classes=2)\n",
    "# @_create_dataset_directory(dataset_name=DATASET_NAME) # uncomment when working on your own directories\n",
    "@_wrap_split_argument(('train', 'test'))\n",
    "def RTPolarity(root, split):\n",
    "    path = root # bad function def. but pytorch function does not accept 3 inputs\n",
    "    return _RawTextIterableDataset(DATASET_NAME, NUM_LINES[split],\n",
    "                                   _create_data_from_csv(root+filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb01de9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-12T21:00:43.468685Z",
     "iopub.status.busy": "2022-01-12T21:00:43.467971Z",
     "iopub.status.idle": "2022-01-12T21:00:43.473474Z",
     "shell.execute_reply": "2022-01-12T21:00:43.474754Z",
     "shell.execute_reply.started": "2022-01-12T20:37:27.647214Z"
    },
    "papermill": {
     "duration": 0.031264,
     "end_time": "2022-01-12T21:00:43.475005",
     "exception": false,
     "start_time": "2022-01-12T21:00:43.443741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8662\n"
     ]
    }
   ],
   "source": [
    "train_iter = RTPolarity(root = root, split = \"train\")\n",
    "print(len(train_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8f38e00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-12T21:00:43.520076Z",
     "iopub.status.busy": "2022-01-12T21:00:43.518975Z",
     "iopub.status.idle": "2022-01-12T21:00:43.524495Z",
     "shell.execute_reply": "2022-01-12T21:00:43.523877Z",
     "shell.execute_reply.started": "2022-01-12T20:37:28.649263Z"
    },
    "papermill": {
     "duration": 0.029897,
     "end_time": "2022-01-12T21:00:43.524657",
     "exception": false,
     "start_time": "2022-01-12T21:00:43.494760",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 'simplistic , silly and tedious . ')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82c48c1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-12T21:00:43.572075Z",
     "iopub.status.busy": "2022-01-12T21:00:43.571289Z",
     "iopub.status.idle": "2022-01-12T21:04:48.168641Z",
     "shell.execute_reply": "2022-01-12T21:04:48.169184Z",
     "shell.execute_reply.started": "2022-01-12T20:43:41.111630Z"
    },
    "papermill": {
     "duration": 244.624066,
     "end_time": "2022-01-12T21:04:48.169668",
     "exception": false,
     "start_time": "2022-01-12T21:00:43.545602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/glove.6B.zip: 862MB [02:42, 5.29MB/s]                           \n",
      "100%|█████████▉| 399999/400000 [00:53<00:00, 7413.37it/s]\n"
     ]
    }
   ],
   "source": [
    "# import tokenizer and pretrained word embeddings\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "from torchtext.vocab import GloVe\n",
    "glove = GloVe(name='6B', dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4354596",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-12T21:04:48.786540Z",
     "iopub.status.busy": "2022-01-12T21:04:48.785531Z",
     "iopub.status.idle": "2022-01-12T21:04:48.788118Z",
     "shell.execute_reply": "2022-01-12T21:04:48.788634Z",
     "shell.execute_reply.started": "2022-01-12T20:47:58.792337Z"
    },
    "papermill": {
     "duration": 0.314591,
     "end_time": "2022-01-12T21:04:48.788821",
     "exception": false,
     "start_time": "2022-01-12T21:04:48.474230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def yield_tokens(data_iter):\n",
    "    for _, text in data_iter:\n",
    "        yield tokenizer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df0d037d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-12T21:04:49.407326Z",
     "iopub.status.busy": "2022-01-12T21:04:49.406612Z",
     "iopub.status.idle": "2022-01-12T21:04:49.842161Z",
     "shell.execute_reply": "2022-01-12T21:04:49.841484Z",
     "shell.execute_reply.started": "2022-01-12T20:48:00.757615Z"
    },
    "papermill": {
     "duration": 0.750061,
     "end_time": "2022-01-12T21:04:49.842310",
     "exception": false,
     "start_time": "2022-01-12T21:04:49.092249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create vocabulary for the dataset \n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\", \"<pad>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e472989",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-12T21:04:50.489133Z",
     "iopub.status.busy": "2022-01-12T21:04:50.488132Z",
     "iopub.status.idle": "2022-01-12T21:04:50.491552Z",
     "shell.execute_reply": "2022-01-12T21:04:50.492209Z",
     "shell.execute_reply.started": "2022-01-12T20:48:02.202014Z"
    },
    "papermill": {
     "duration": 0.332829,
     "end_time": "2022-01-12T21:04:50.492384",
     "exception": false,
     "start_time": "2022-01-12T21:04:50.159555",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 264]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab([\"<unk>\", \"<pad>\", \"silly\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09fba626",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-12T21:04:51.137760Z",
     "iopub.status.busy": "2022-01-12T21:04:51.136808Z",
     "iopub.status.idle": "2022-01-12T21:04:51.141524Z",
     "shell.execute_reply": "2022-01-12T21:04:51.142144Z",
     "shell.execute_reply.started": "2022-01-12T20:48:04.243245Z"
    },
    "papermill": {
     "duration": 0.332909,
     "end_time": "2022-01-12T21:04:51.142320",
     "exception": false,
     "start_time": "2022-01-12T21:04:50.809411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getMxLen(data_iter):\n",
    "    MAXLEN = 0\n",
    "    for _, text in data_iter:\n",
    "        tmp = tokenizer(text)\n",
    "        if(len(tmp) > MAXLEN):\n",
    "            MAXLEN = len(tmp)\n",
    "    return MAXLEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bd49ed4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-12T21:04:51.800959Z",
     "iopub.status.busy": "2022-01-12T21:04:51.800184Z",
     "iopub.status.idle": "2022-01-12T21:04:52.048147Z",
     "shell.execute_reply": "2022-01-12T21:04:52.049166Z",
     "shell.execute_reply.started": "2022-01-12T20:51:40.055234Z"
    },
    "papermill": {
     "duration": 0.587356,
     "end_time": "2022-01-12T21:04:52.049472",
     "exception": false,
     "start_time": "2022-01-12T21:04:51.462116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sentence length is  62\n"
     ]
    }
   ],
   "source": [
    "train_iter = RTPolarity(root = root, split = \"train\")\n",
    "MAXLEN = getMxLen(train_iter)\n",
    "print(\"Maximum sentence length is \", MAXLEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4adb51f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-12T21:04:52.770462Z",
     "iopub.status.busy": "2022-01-12T21:04:52.769040Z",
     "iopub.status.idle": "2022-01-12T21:04:52.774428Z",
     "shell.execute_reply": "2022-01-12T21:04:52.775089Z",
     "shell.execute_reply.started": "2022-01-12T20:51:59.848855Z"
    },
    "papermill": {
     "duration": 0.353613,
     "end_time": "2022-01-12T21:04:52.775277",
     "exception": false,
     "start_time": "2022-01-12T21:04:52.421664",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the pipelines\n",
    "text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "label_pipeline = lambda x: int(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "957cce5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-12T21:04:53.478149Z",
     "iopub.status.busy": "2022-01-12T21:04:53.476593Z",
     "iopub.status.idle": "2022-01-12T21:04:53.488299Z",
     "shell.execute_reply": "2022-01-12T21:04:53.488993Z",
     "shell.execute_reply.started": "2022-01-12T20:52:17.611764Z"
    },
    "papermill": {
     "duration": 0.381107,
     "end_time": "2022-01-12T21:04:53.489181",
     "exception": false,
     "start_time": "2022-01-12T21:04:53.108074",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "device = \"cpu\" #torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# batch collator for torch dataloaders\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list = [], []\n",
    "    for (_label, _text) in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "        #print(processed_text.shape)\n",
    "        # add padding here \n",
    "        pp = torch.ones([MAXLEN - processed_text.shape[0]])\n",
    "        text_list.append(torch.cat((processed_text, pp)))\n",
    "        # offsets.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    # offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text_list = torch.stack(text_list).int()\n",
    "    return label_list.to(device), text_list.to(device)\n",
    "train_iter = RTPolarity(split=\"train\")\n",
    "train_dataloader = DataLoader(train_iter, batch_size=8, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "065fff47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-12T21:04:54.178971Z",
     "iopub.status.busy": "2022-01-12T21:04:54.177713Z",
     "iopub.status.idle": "2022-01-12T21:04:54.951232Z",
     "shell.execute_reply": "2022-01-12T21:04:54.951800Z",
     "shell.execute_reply.started": "2022-01-12T20:52:53.838527Z"
    },
    "papermill": {
     "duration": 1.118978,
     "end_time": "2022-01-12T21:04:54.951998",
     "exception": false,
     "start_time": "2022-01-12T21:04:53.833020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8]) torch.Size([8, 62])\n"
     ]
    }
   ],
   "source": [
    "# get samples from a dataloder\n",
    "import torch\n",
    "train_iter = RTPolarity(root = root, split=\"train\")\n",
    "train_dataloader = DataLoader(train_iter, batch_size=8, shuffle=False, collate_fn=collate_batch)\n",
    "ty = None\n",
    "tx = None\n",
    "shape = None\n",
    "cnt = 0\n",
    "for y, X in train_dataloader:\n",
    "    if(cnt == 0):\n",
    "      ty, tx = y, X\n",
    "      print(ty.shape, tx.shape)\n",
    "      shapex = tx.shape\n",
    "      shapey = ty.shape\n",
    "    assert(shapex == tx.shape)\n",
    "    assert(shapey == ty.shape)\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d9c838b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-12T21:04:55.636940Z",
     "iopub.status.busy": "2022-01-12T21:04:55.634114Z",
     "iopub.status.idle": "2022-01-12T21:04:56.102049Z",
     "shell.execute_reply": "2022-01-12T21:04:56.102835Z",
     "shell.execute_reply.started": "2022-01-12T20:53:07.399794Z"
    },
    "papermill": {
     "duration": 0.815202,
     "end_time": "2022-01-12T21:04:56.103072",
     "exception": false,
     "start_time": "2022-01-12T21:04:55.287870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18339, 300) 18339\n"
     ]
    }
   ],
   "source": [
    "# create embedding matrix \n",
    "matrix_len = len(vocab)\n",
    "weights_matrix = np.zeros((matrix_len, 300))\n",
    "words_found = 0\n",
    "\n",
    "for i, word in enumerate(vocab.get_itos()):\n",
    "    try: \n",
    "        weights_matrix[i] = glove.get_vecs_by_tokens(word)\n",
    "        words_found += 1\n",
    "    except KeyError:\n",
    "        weights_matrix[i] = glove.get_vecs_by_tokens(\"<unk>\")\n",
    "print(weights_matrix.shape, words_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c2e4ef4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-12T21:04:56.727725Z",
     "iopub.status.busy": "2022-01-12T21:04:56.723531Z",
     "iopub.status.idle": "2022-01-12T21:04:56.729642Z",
     "shell.execute_reply": "2022-01-12T21:04:56.730245Z",
     "shell.execute_reply.started": "2022-01-12T20:53:18.529132Z"
    },
    "papermill": {
     "duration": 0.317536,
     "end_time": "2022-01-12T21:04:56.730447",
     "exception": false,
     "start_time": "2022-01-12T21:04:56.412911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# defining the embedding layer\n",
    "import torch.nn as nn\n",
    "def create_emb_layer(weights_matrix, freeze = True):\n",
    "    num_embeddings, embedding_dim = weights_matrix.shape[0], weights_matrix.shape[1]\n",
    "    emb_layer = nn.Embedding.from_pretrained(torch.Tensor(weights_matrix), freeze = freeze, sparse = True)\n",
    "    #emb_layer.load_state_dict({'weight': weights_matrix})\n",
    "\n",
    "    return emb_layer, num_embeddings, embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a332932",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-12T21:04:57.358172Z",
     "iopub.status.busy": "2022-01-12T21:04:57.357263Z",
     "iopub.status.idle": "2022-01-12T21:04:57.366418Z",
     "shell.execute_reply": "2022-01-12T21:04:57.367024Z",
     "shell.execute_reply.started": "2022-01-12T20:55:13.587491Z"
    },
    "papermill": {
     "duration": 0.328705,
     "end_time": "2022-01-12T21:04:57.367210",
     "exception": false,
     "start_time": "2022-01-12T21:04:57.038505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, weights_matrix):\n",
    "        # define the attributes (class members)\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.embedding, num_embeddings, embedding_dim = create_emb_layer(weights_matrix, True)\n",
    "        print(num_embeddings, embedding_dim)\n",
    "        trans_enc_layer = nn.TransformerEncoderLayer(d_model = embedding_dim, nhead = 3 ,batch_first=True)\n",
    "        self.transformer = nn.TransformerEncoder(trans_enc_layer, num_layers=2)\n",
    "        self.fc1 = nn.Linear(18600, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.flatten = nn.Flatten()\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.transformer(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6074f754",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-12T21:04:57.997347Z",
     "iopub.status.busy": "2022-01-12T21:04:57.996701Z",
     "iopub.status.idle": "2022-01-12T21:04:58.051734Z",
     "shell.execute_reply": "2022-01-12T21:04:58.052229Z",
     "shell.execute_reply.started": "2022-01-12T20:55:15.003847Z"
    },
    "papermill": {
     "duration": 0.373551,
     "end_time": "2022-01-12T21:04:58.052414",
     "exception": false,
     "start_time": "2022-01-12T21:04:57.678863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18339 300\n",
      "NeuralNetwork(\n",
      "  (embedding): Embedding(18339, 300, sparse=True)\n",
      "  (transformer): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=300, out_features=300, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=300, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=300, bias=True)\n",
      "        (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=300, out_features=300, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=300, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=300, bias=True)\n",
      "        (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (fc1): Linear(in_features=18600, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (relu): ReLU()\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n",
      "Number of trainable parameters is  3205697\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(weights_matrix)\n",
    "print(model)\n",
    "print(\"Number of trainable parameters is \", \n",
    "      sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0235954d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-12T21:04:58.681578Z",
     "iopub.status.busy": "2022-01-12T21:04:58.680803Z",
     "iopub.status.idle": "2022-01-12T21:04:58.691740Z",
     "shell.execute_reply": "2022-01-12T21:04:58.691001Z",
     "shell.execute_reply.started": "2022-01-12T20:54:13.035729Z"
    },
    "papermill": {
     "duration": 0.329824,
     "end_time": "2022-01-12T21:04:58.691902",
     "exception": false,
     "start_time": "2022-01-12T21:04:58.362078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(dataloader):\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    log_interval = 100\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (label, text) in enumerate(dataloader):\n",
    "        label, text = label.to(device), text.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        predicted_label = model(text)\n",
    "        loss = criterion(predicted_label, label.reshape(-1,1).float())\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
    "                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
    "                                              total_acc/total_count))\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text) in enumerate(dataloader):\n",
    "            label, text = label.to(device), text.to(device)\n",
    "            predicted_label = model(text)\n",
    "            loss = criterion(predicted_label, label.reshape(-1,1).float())\n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98f757c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-12T21:04:59.331365Z",
     "iopub.status.busy": "2022-01-12T21:04:59.330677Z",
     "iopub.status.idle": "2022-01-12T21:06:55.677502Z",
     "shell.execute_reply": "2022-01-12T21:06:55.678053Z",
     "shell.execute_reply.started": "2022-01-12T20:56:12.183833Z"
    },
    "papermill": {
     "duration": 116.673081,
     "end_time": "2022-01-12T21:06:55.678311",
     "exception": false,
     "start_time": "2022-01-12T21:04:59.005230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   100/  515 batches | accuracy    0.637\n",
      "| epoch   1 |   200/  515 batches | accuracy    0.608\n",
      "| epoch   1 |   300/  515 batches | accuracy    0.618\n",
      "| epoch   1 |   400/  515 batches | accuracy    0.603\n",
      "| epoch   1 |   500/  515 batches | accuracy    0.621\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time: 116.26s | valid accuracy    0.601 \n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "# Hyperparameters\n",
    "EPOCHS = 1 # epoch\n",
    "LR = 0.001  # learning rate\n",
    "BATCH_SIZE = 16 # batch size for training\n",
    "\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
    "total_accu = None\n",
    "train_iter, test_iter = RTPolarity(root = root)\n",
    "train_dataset = to_map_style_dataset(train_iter)\n",
    "test_dataset = to_map_style_dataset(test_iter)\n",
    "num_train = int(len(train_dataset) * 0.95)\n",
    "split_train_, split_valid_ = \\\n",
    "    random_split(train_dataset, [num_train, len(train_dataset) - num_train])\n",
    "\n",
    "train_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "valid_dataloader = DataLoader(split_valid_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
    "                             shuffle=True, collate_fn=collate_batch)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(train_dataloader)\n",
    "    accu_val = evaluate(valid_dataloader)\n",
    "    if total_accu is not None and total_accu > accu_val:\n",
    "      scheduler.step()\n",
    "    else:\n",
    "       total_accu = accu_val\n",
    "    print('-' * 59)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
    "          'valid accuracy {:8.3f} '.format(epoch,\n",
    "                                           time.time() - epoch_start_time,\n",
    "                                           accu_val))\n",
    "    print('-' * 59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab5b021",
   "metadata": {
    "papermill": {
     "duration": 0.317261,
     "end_time": "2022-01-12T21:06:56.329314",
     "exception": false,
     "start_time": "2022-01-12T21:06:56.012053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 388.367527,
   "end_time": "2022-01-12T21:06:57.869340",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-01-12T21:00:29.501813",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
